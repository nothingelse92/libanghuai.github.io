<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Few-shot Adaptive Faster R-CNN"><meta name="keywords" content="Object Detection,Few Shot,Domain Adaptation"><meta name="author" content="Out of Memory,undefined"><meta name="copyright" content="Out of Memory"><title>Few-shot Adaptive Faster R-CNN【Out of Memory】</title><link rel="stylesheet" href="../../../../css/fan.css"><link rel="stylesheet" href="../../../../css/thirdparty/jquery.mCustomScrollbar.min.css"><link rel="icon" href="../../../../favicon.ico"><!-- script(src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML")--><script src="../../../../js/mathjax/mathjax.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
});
</script><script>var isPassword = '' || false;
if (isPassword) {
    if (prompt('请输入文章密码') !== '') {
        alert('密码错误！');
        history.back();
    }
}</script><script>window.GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
}</script></head><body><canvas id="universe"></canvas><!--#body--><div id="sidebar"><div class="toggle-sidebar-info button-hover"><span data-toggle="文章目录">站点概览</span></div><div class="sidebar-toc"><div class="sidebar-toc-title">目录</div><div class="sidebar-toc-progress"><span class="progress-notice">您已阅读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc-progress-bar"></div></div><div class="sidebar-toc-content" id="sidebar-toc-content"></div></div><div class="author-info hide"><div class="author-info-avatar"><img class="author-info-avatar-img" src="/avatar.png"></div><div class="author-info-name">Out of Memory</div><div class="author-info-description">Live and Learn</div><div class="links-buttons"><a class="links-button button-hover" href="https://github.com/libanghuai" target="_blank">GitHub<i class="icon-dot bg-color8"></i></a><a class="links-button button-hover" href="mailto:libanghuai@gmail.com" target="_blank">E-Mail<i class="icon-dot bg-color9"></i></a><a class="links-button button-hover" href="tencent://message/?uin=1185719433&amp;Site=&amp;Menu=yes" target="_blank">QQ<i class="icon-dot bg-color3"></i></a></div><div class="author-info-articles"><a class="author-info-articles-archives article-meta" href="../../../../archives"><span class="pull-top">日志</span><span class="pull-bottom">106</span></a><a class="author-info-articles-tags article-meta" href="../../../../tags"><span class="pull-top">标签</span><span class="pull-bottom">36</span></a></div></div></div><div id="main-container"><header><div id="menu-outer"><i class="menu-list-icon fas fa-bars"></i><nav id="menu-inner"><a class="menu-item" href="/">首页</a><a class="menu-item" href="/tags">标签</a><a class="menu-item" href="/categories">分类</a><a class="menu-item" href="/archives">归档</a><a class="menu-item" href="/about">关于</a></nav><div class="right-info"><a class="title-name" href="/">Out of Memory</a><span id="now-time"></span></div></div></header><div id="content-outer"><div id="content-inner"><article id="post"><div class="post-header"><div class="title">Few-shot Adaptive Faster R-CNN</div><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 发表于 2020-02-25 | 更新于 2020-03-12</time><!--time.button-hover.post-date #[i.fas.fa-calendar-alt.article-icon(aria-hidden="true")] #[=__('post.modified')] #[=date(page['updated'], config.date_format)]--><div class="button-hover categories"></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="../../../../tags/Object-Detection/">Object Detection</a><span>&nbsp;|&nbsp;</span><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="../../../../tags/Few-Shot/">Few Shot</a><span>&nbsp;|&nbsp;</span><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="../../../../tags/Domain-Adaptation/">Domain Adaptation</a></div></div></div><div class="main-content"><p>URL: <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Few-Shot_Adaptive_Faster_R-CNN_CVPR_2019_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Few-Shot_Adaptive_Faster_R-CNN_CVPR_2019_paper.pdf</a></p>
<p>CVPR 2019的论文，这篇比较好的地方是在abstract部分就直接阐明了目前few shot问题存在的几个根本问题，我也比较认可论文提到的这几个痛点：</p>
<ol>
<li>target domain数据量很少，从任务本身来说就比较难，从一个domain transfer到另一个domain，在如此受限的数据情况下</li>
<li>同样也因为target domain数据量很少，导致过拟合问题是一个不得不处理的事情</li>
<li>few shot for detection目前来看实际工作不是很多，因为detection任务需要兼顾object定位和分类，所以任务本身上看比较难</li>
</ol>
<p>我们具体看下这篇论文是怎么做的，整体PPL看上去还是比较复杂的:</p>
<p><img src="Few-shot-Adaptive-Faster-R-CNN-屏幕快照 2020-02-28 下午2.41.16.png" alt=""></p>
<p>从大面上论文主要分成2个部分:</p>
<ol>
<li><strong>Image Level Domain Adaptation</strong>: 上图的上半部分就是Image Level Domain Adaptation部分，这里引入了一个SP操作（Split Pooling），这个主要是作者参考已有的论文结论觉得局部的patch可以更好的表示图片的特征。做法呢也比较简单，有一个初始框(w,h),随机再生成两个shift(δ<sub>w</sub>, δ<sub>h</sub>，这是相比较图像左上角的偏移)，这样就可以组成一个明确位置和大小的框了，然后因为是基于anchor的检测框架，所有这里的(w, h)是和anchor scale/anchor ratio保持一致的，论文里是给了9个框(3个ratio x 3个scale)，这样最后可以抽出9个patch的feature。那么论文的<strong>Pair Sampling</strong>则是GAN类似的对抗学习的过程，我们把这9个patch feature按照scale大小分成larege、medium、small三大部分，然后每一个部分分别来对抗学习，对于每一个部分组成两组pair:{s,s}, {s,t}(s代表source image,t代表target image)，然后GAN要学习的就是区分开这两者。</li>
<li><strong>Instance Level Domain Adaptation</strong>: 上图的中间部分可以理解为正常的Faster RCNN逻辑，而下半部分就可以理解为这里的Instance Level Domain Adaptation，这一部分的作用倒也可以理解，adaptation的粒度不一样，这里作者提了一个概念叫<em>Instance ROI Sampling</em>. 相比较普通的ROI Sampling主要的差别就是IOU卡的很高(&gt;0.7)这样得到的ROI更加贴近Install本身，另外就是所有的Positive都会送入到下一阶段做判断，而不是一般的RPN在处理的时候会控制前背景的比例，然后至于怎么去用GAN去区分就和<em>Image Level Domain Adaptation</em>里面提到的<strong>Pair Sampling</strong>逻辑是一摸一样的了。</li>
</ol>
<p>那么针对作者提出的过拟合问题，论文了也给了一个解法:<strong>Source Model Feature Regularization Training</strong>. 想法比较直接，现在论文提出的FAFRCNN方法是针对src + target domain的，作者另外训练一个source domain的detector，然后给定相同的souce domain的数据让这两个模型提取出来的特征尽可能相近：</p>
<p><img src="Few-shot-Adaptive-Faster-R-CNN-屏幕快照 2020-03-10 下午12.57.14.png" alt=""></p>
<p>然后论文的主要内容大概就这些，整体ppl有点太复杂不太实用。</p>
</div><div class="post-copyright"><div class="post-copyright-author"><span class="post-copyright-meta">本文作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Out of Memory</a></span></div><div class="post-copyright-type"><span class="post-copyright-meta">本文链接: </span><span class="post-copyright-info"><a href="http://libanghuai.com/2020/02/25/Few-shot-Adaptive-Faster-R-CNN/">http://libanghuai.com/2020/02/25/Few-shot-Adaptive-Faster-R-CNN/</a></span></div><div class="post-copyright-notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://libanghuai.com">Out of Memory</a>！</span></div></div></article><div id="pagination"><div class="prev-post pull-left"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="../../28/Few-shot-Object-Detection-via-Feature-Reweighting/"><i class="fas fa-angle-left">&nbsp;</i><span>Few-shot Object Detection via Feature Reweighting</span></a></div><div class="next-post pull-right"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="../../22/Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregation-for-Scene-Segmentation/"><span>Context Contrasted Feature and Gated Multi-scale Aggregation for Scene Segmentation</span><span>&nbsp;</span><i class="fas fa-angle-right"></i></a></div></div><!--div!= paginator()--></div></div><div class="button-hover" id="return-top"><i class="fas fa-arrow-up" aria-hidden="true"></i></div><footer><div id="footer"><div class="button-hover" id="side-button"><i class="fas fa-arrow-right"></i></div><div class="right-content"><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fas fa-file-o"></i></span><span id="busuanzi_value_page_pv"></span><span></span></div><div class="copyright">&copy;2017 ～ 2020 By Out of Memory</div></div></div></footer></div><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/thirdparty/jquery-3.3.1.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/thirdparty/velocity.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/thirdparty/jquery.mCustomScrollbar.concat.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/fan.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/canvas_bg.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/utils.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/scroll.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/sidebar.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/copy.js"></script><!--script(src=url)--></body></html>