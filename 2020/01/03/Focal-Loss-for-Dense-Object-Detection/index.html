<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Focal Loss for Dense Object Detection"><meta name="keywords" content="Loss,Object Detection,Classic"><meta name="author" content="Out of Memory,undefined"><meta name="copyright" content="Out of Memory"><title>Focal Loss for Dense Object Detection【Out of Memory】</title><link rel="stylesheet" href="../../../../css/fan.css"><link rel="stylesheet" href="../../../../css/thirdparty/jquery.mCustomScrollbar.min.css"><link rel="icon" href="../../../../favicon.ico"><!-- script(src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML")--><script src="../../../../js/mathjax/mathjax.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
});
</script><script>var isPassword = '' || false;
if (isPassword) {
    if (prompt('请输入文章密码') !== '') {
        alert('密码错误！');
        history.back();
    }
}</script><script>window.GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
}</script></head><body><canvas id="universe"></canvas><!--#body--><div id="sidebar"><div class="toggle-sidebar-info button-hover"><span data-toggle="文章目录">站点概览</span></div><div class="sidebar-toc"><div class="sidebar-toc-title">目录</div><div class="sidebar-toc-progress"><span class="progress-notice">您已阅读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc-progress-bar"></div></div><div class="sidebar-toc-content" id="sidebar-toc-content"></div></div><div class="author-info hide"><div class="author-info-avatar"><img class="author-info-avatar-img" src="/avatar.png"></div><div class="author-info-name">Out of Memory</div><div class="author-info-description">Live and Learn</div><div class="links-buttons"><a class="links-button button-hover" href="https://github.com/libanghuai" target="_blank">GitHub<i class="icon-dot bg-color6"></i></a><a class="links-button button-hover" href="mailto:libanghuai@gmail.com" target="_blank">E-Mail<i class="icon-dot bg-color2"></i></a><a class="links-button button-hover" href="tencent://message/?uin=1185719433&amp;Site=&amp;Menu=yes" target="_blank">QQ<i class="icon-dot bg-color7"></i></a></div><div class="author-info-articles"><a class="author-info-articles-archives article-meta" href="../../../../archives"><span class="pull-top">日志</span><span class="pull-bottom">100</span></a><a class="author-info-articles-tags article-meta" href="../../../../tags"><span class="pull-top">标签</span><span class="pull-bottom">34</span></a><a class="author-info-articles-categories article-meta" href="../../../../categories"><span class="pull-top">分类</span><span class="pull-bottom">1</span></a></div></div></div><div id="main-container"><header><div id="menu-outer"><i class="menu-list-icon fas fa-bars"></i><nav id="menu-inner"><a class="menu-item" href="/">首页</a><a class="menu-item" href="/tags">标签</a><a class="menu-item" href="/categories">分类</a><a class="menu-item" href="/archives">归档</a><a class="menu-item" href="/about">关于</a></nav><div class="right-info"><a class="title-name" href="/">Out of Memory</a><span id="now-time"></span></div></div></header><div id="content-outer"><div id="content-inner"><article id="post"><div class="post-header"><div class="title">Focal Loss for Dense Object Detection</div><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 发表于 2020-01-03 | 更新于 2020-01-03</time><!--time.button-hover.post-date #[i.fas.fa-calendar-alt.article-icon(aria-hidden="true")] #[=__('post.modified')] #[=date(page['updated'], config.date_format)]--><div class="button-hover categories"></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="../../../../tags/Loss/">Loss</a><span>&nbsp;|&nbsp;</span><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="../../../../tags/Object-Detection/">Object Detection</a><span>&nbsp;|&nbsp;</span><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="../../../../tags/Classic/">Classic</a></div></div></div><div class="main-content"><p>URL: <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Lin_Focal_Loss_for_ICCV_2017_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ICCV_2017/papers/Lin_Focal_Loss_for_ICCV_2017_paper.pdf</a></p>
<p>重读经典系列第三篇：RetinaNet</p>
<p>ICCV 2017的Best Student Paper,也是 He Kaiming一篇很有代表性的工作，论文主要focus在One Stage Detector中样本不均衡这件事上，并且提出了<strong>Focal Loss</strong>来解决这样的问题，同时基于Focal Loss实现了一个One Stage Detector <strong>RetinaNet</strong>,可以达到Two Stage Detector的精度同时可以保持One Stage Detector的速度。</p>
<p>我们知道Two Stage Detector精度高速度慢，One Stage Detector速度快精度低，这几乎是所有人可以脱口而出的特性，那么作者认为One Stage Detector精度低的主要原因就是非常严重的class imbalance问题，基于anchor的检测器动则有10W+的anchor数目，其中Positive的anchor只有几十个，这样正负样本比几乎可以达到1:1000，大量的负样本中有很多的easy negative samples它们对模型的训练几乎无法贡献有效的信息,同时大量的这种样本本身对模型的训练也是很有害的，毕竟它们占据主要部分容易主导模型的训练。因此作者提出了Focal Loss：<br><strong>FL(p<sub>t</sub>) = −α<sub>t</sub>(1 − p<sub>t</sub>)<sup>γ</sup> log(p<sub>t</sub>)</strong><br>那么Focal Loss本身呢是来自于Cross Entropy Loss(以二分类为例):<br><img src="Focal-Loss-for-Dense-Object-Detection-屏幕快照 2020-01-03 下午8.14.46.png" alt=""><br>稍微简化一下：<br><img src="Focal-Loss-for-Dense-Object-Detection-屏幕快照 2020-01-03 下午8.15.32.png" alt=""><br>那么CE(p, y) = CE(p<sub>t</sub>) = − log(p<sub>t</sub>)<br>那么我们再来看看Focal Loss在CE Loss基础上增加的东西：</p>
<ol>
<li>−α<sub>t</sub>: 这就是简单的一个类别权重，比如可以将正样本的权重加大也是缓解class imbalance的一个选择</li>
<li>(1 − p<sub>t</sub>)<sup>γ</sup> : 这个可以理解为Focal Loss的核心吧，会整体通过模型的预测值动态的去调整loss的权重，如果某一个sample模型预测的类别是错误的那就意味着p<sub>t</sub>值会比较小（注意看p<sub>t</sub>的定义，对于每一个类别都是如此），那么Focal Loss整体就会和CE Loss差不多不会有什么影响，如果一个easy sample可以被模型很好的分类那么意味着p<sub>t</sub>值会比较大，那么Loss的权重就会变小从而优化过程中不会刻意处理，因此整个模型训练过程中都会刻意去优化hard sample。其中γ是平滑系数，论文中通过尝试γ = 2效果会比较好.</li>
</ol>
<p>至于论文中提到的RetinaNet整体其实没有什么特殊的，具体结构如下，是一个FPN的结构：<br><img src="Focal-Loss-for-Dense-Object-Detection-屏幕快照 2020-01-03 下午8.42.36.png" alt=""><br>需要注意的是:</p>
<ol>
<li>class subnet 和 box subnet参数在P3 - P7之间是共享的</li>
<li>P3 - P5通过Conv来源于C3 - C5，P6通过Conv来源于P5，P7通过Conv来源于P6</li>
<li>P3 - P7的结果会concat到一起最后一起NMS</li>
<li>为了训练的稳定性初始化有一些trick具体可以参考原论文</li>
</ol>
</div><div class="post-copyright"><div class="post-copyright-author"><span class="post-copyright-meta">本文作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Out of Memory</a></span></div><div class="post-copyright-type"><span class="post-copyright-meta">本文链接: </span><span class="post-copyright-info"><a href="http://libanghuai.com/2020/01/03/Focal-Loss-for-Dense-Object-Detection/">http://libanghuai.com/2020/01/03/Focal-Loss-for-Dense-Object-Detection/</a></span></div><div class="post-copyright-notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://libanghuai.com">Out of Memory</a>！</span></div></div></article><div id="pagination"><div class="prev-post pull-left"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="../../07/FCOS-Fully-Convolutional-One-Stage-Object-Detection/"><i class="fas fa-angle-left">&nbsp;</i><span>FCOS: Fully Convolutional One-Stage Object Detection</span></a></div><div class="next-post pull-right"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="../../../../2019/12/30/ACNet-Strengthening-the-Kernel-Skeletons-for-Powerful-CNN-via-Asymmetric-Convolution-Blocks/"><span>ACNet: Strengthening the Kernel Skeletons for Powerful CNN via Asymmetric Convolution Blocks</span><span>&nbsp;</span><i class="fas fa-angle-right"></i></a></div></div><!--div!= paginator()--></div></div><div class="button-hover" id="return-top"><i class="fas fa-arrow-up" aria-hidden="true"></i></div><footer><div id="footer"><div class="button-hover" id="side-button"><i class="fas fa-arrow-right"></i></div><div class="right-content"><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fas fa-file-o"></i></span><span id="busuanzi_value_page_pv"></span><span></span></div><div class="copyright">&copy;2017 ～ 2020 By Out of Memory</div></div></div></footer></div><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/thirdparty/jquery-3.3.1.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/thirdparty/velocity.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/thirdparty/jquery.mCustomScrollbar.concat.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/fan.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/canvas_bg.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/utils.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/scroll.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/sidebar.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/copy.js"></script><!--script(src=url)--></body></html>