<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="FCOS: Fully Convolutional One-Stage Object Detection"><meta name="keywords" content="Object Detection,Classic"><meta name="author" content="Out of Memory,undefined"><meta name="copyright" content="Out of Memory"><title>FCOS: Fully Convolutional One-Stage Object Detection【Out of Memory】</title><link rel="stylesheet" href="../../../../css/fan.css"><link rel="stylesheet" href="../../../../css/thirdparty/jquery.mCustomScrollbar.min.css"><link rel="icon" href="../../../../favicon.ico"><!-- script(src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML")--><script src="../../../../js/mathjax/mathjax.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
});
</script><script>var isPassword = '' || false;
if (isPassword) {
    if (prompt('请输入文章密码') !== '') {
        alert('密码错误！');
        history.back();
    }
}</script><script>window.GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
}</script></head><body><canvas id="universe"></canvas><!--#body--><div id="sidebar"><div class="toggle-sidebar-info button-hover"><span data-toggle="文章目录">站点概览</span></div><div class="sidebar-toc"><div class="sidebar-toc-title">目录</div><div class="sidebar-toc-progress"><span class="progress-notice">您已阅读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc-progress-bar"></div></div><div class="sidebar-toc-content" id="sidebar-toc-content"></div></div><div class="author-info hide"><div class="author-info-avatar"><img class="author-info-avatar-img" src="/avatar.png"></div><div class="author-info-name">Out of Memory</div><div class="author-info-description">Live and Learn</div><div class="links-buttons"><a class="links-button button-hover" href="https://github.com/libanghuai" target="_blank">GitHub<i class="icon-dot bg-color2"></i></a><a class="links-button button-hover" href="mailto:libanghuai@gmail.com" target="_blank">E-Mail<i class="icon-dot bg-color9"></i></a><a class="links-button button-hover" href="tencent://message/?uin=1185719433&amp;Site=&amp;Menu=yes" target="_blank">QQ<i class="icon-dot bg-color5"></i></a></div><div class="author-info-articles"><a class="author-info-articles-archives article-meta" href="../../../../archives"><span class="pull-top">日志</span><span class="pull-bottom">99</span></a><a class="author-info-articles-tags article-meta" href="../../../../tags"><span class="pull-top">标签</span><span class="pull-bottom">34</span></a><a class="author-info-articles-categories article-meta" href="../../../../categories"><span class="pull-top">分类</span><span class="pull-bottom">2</span></a></div></div></div><div id="main-container"><header><div id="menu-outer"><i class="menu-list-icon fas fa-bars"></i><nav id="menu-inner"><a class="menu-item" href="/">首页</a><a class="menu-item" href="/tags">标签</a><a class="menu-item" href="/categories">分类</a><a class="menu-item" href="/archives">归档</a><a class="menu-item" href="/about">关于</a></nav><div class="right-info"><a class="title-name" href="/">Out of Memory</a><span id="now-time"></span></div></div></header><div id="content-outer"><div id="content-inner"><article id="post"><div class="post-header"><div class="title">FCOS: Fully Convolutional One-Stage Object Detection</div><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 发表于 2020-01-07 | 更新于 2020-01-12</time><!--time.button-hover.post-date #[i.fas.fa-calendar-alt.article-icon(aria-hidden="true")] #[=__('post.modified')] #[=date(page['updated'], config.date_format)]--><div class="button-hover categories"></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="../../../../tags/Object-Detection/">Object Detection</a><span>&nbsp;|&nbsp;</span><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="../../../../tags/Classic/">Classic</a></div></div></div><div class="main-content"><p>URL: <a href="https://arxiv.org/pdf/1904.01355.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1904.01355.pdf</a></p>
<p>2019年备受推崇的一篇anchor free的论文，最后也应该中了ICCV2019，但是对于熟悉检测领域的同学来说，看到这篇论文应该略有眼熟，这篇论文其实和Densebox应该属于一脉相承，都希望利用FCN的逻辑统一检测/分割等任务。</p>
<p>FCOS的具体想法呢是这样的，基于FPN的结构，P3 - P7得到的feature map假设分别是H<sub>i</sub> x W<sub>i</sub> x C<sub>i</sub>，那么基于H x W这么多个pixel，每个pixel都作为一个中心点去回归一个目标bbox，每个bbox的定义同样包含5个值，一个是分类score，一个是回归offset，只是这个offset的值当前这个pixel距离gt框四条边的具体(和anchor based模型一样，feature map的pixel gt的计算只需要按stride映射会原图就好)，具体的示意图如下：</p>
<p><img src="FCOS-Fully-Convolutional-One-Stage-Object-Detection-屏幕快照 2020-01-06 上午12.20.12.png" alt=""></p>
<p>几个需要注意的点:</p>
<ol>
<li>gt的生成，对于feature map上的某个pixel (x, y), 如果(x, y) 映射到原图的点(x<sup>‘</sup>, y<sup>‘</sup>)落在了某个gt框里，那么对应的offset就算(x<sup>‘</sup>, y<sup>‘</sup>)到gt框四条边的offset，分类gt也就沿用这个gt框的class标注。</li>
<li>FPN的好处一是可以fuse feature另外一个不同的layer可以针对性的回归不同scale的框，那么在FCOS中这部分是怎么做的呢，论文将P3 - P7 5个FPN层用6个值进行区间划分 ，论文中是用的区间m = [0, 64, 128, 256, 512 , ∞]，对于一个gt: (l<sup>∗</sup>, t<sup>∗</sup>, r<sup>∗</sup> ,b<sup>∗</sup>),如果满足<br>max(l<sup>∗</sup>, t<sup>∗</sup>, r<sup>∗</sup> ,b<sup>∗</sup>) &gt; m<sub>i</sub> or max(l<sup>∗</sup>, t<sup>∗</sup>, r<sup>∗</sup> ,b<sup>∗</sup>) &lt; m<sub>i - 1</sub>，那么P<sub>3 + i</sub>就会将这个gt视为negative sample，这层不负责回归这个gt框。这么做其实会有一个问题，对于靠近gt框边缘的点有可能会落到其他layer上(也就是一个gt框内所有的pixel不一定都在一个layer里)这其实在某种程度上违背了FPN的初衷，只是在具体的实现的时候似乎可以卡中心的一些ratio来人为的干掉边缘pixel。</li>
<li>FPN另一个好处可以缓解一个pixel对目标回归的不确定性，比如下图，手拿网球拍的运动员，小的蓝色框的大部分pixel同时也落在来橙色的人体框中，这就导致一个问题，这些overlap的pixel具体需要负责去回归哪个框，通过FPN上述的分层处理可以大大缓解这个问题，论文的ablation里是有具体的数据的，感兴趣的同学可以参考原论文，那么假设在这样的情况下还是有少数不确定的pixel，那么这些pixel就负责回顾最小的那个框！</li>
</ol>
<p><img src="FCOS-Fully-Convolutional-One-Stage-Object-Detection-屏幕快照 2020-01-03 下午10.04.06.png" alt=""></p>
<p>论文的最后一段另外还提出了center-ness loss的概念，主要是想解决在具体实验中发现的FCOS会产生大量低质量的框环绕在gt周围（应该都是gt的边缘pixel产生的），因此提出了center-ness loss的概念：</p>
<p><img src="FCOS-Fully-Convolutional-One-Stage-Object-Detection-截屏2020-01-1200.31.54.png" alt=""></p>
<p>我们来看一下这个loss，l<sup>*</sup>和r<sup>*</sup>，t<sup>*</sup>和b<sup>*</sup>是两对相互关联的变量，如果某个pixel越靠近中心点(center)那么这两对值就会越接近，那么center-ness loss就会越趋向于1，如果某个pixel越远离中心点(center)，那么center-ness loss就会越趋向于0.所以可以理解为center-ness是一个度量离中心点越近的单位，inference的时候这个center-ness分支的结果会加权于score从而约束了偏离中心点的pixel，也抑制了大量低质量的框。</p>
<p>论文整体的内容应该就这些了，FCOS对后续的anchor free做法还是很有启发意义的。</p>
</div><div class="post-copyright"><div class="post-copyright-author"><span class="post-copyright-meta">本文作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Out of Memory</a></span></div><div class="post-copyright-type"><span class="post-copyright-meta">本文链接: </span><span class="post-copyright-info"><a href="http://libanghuai.com/2020/01/07/FCOS-Fully-Convolutional-One-Stage-Object-Detection/">http://libanghuai.com/2020/01/07/FCOS-Fully-Convolutional-One-Stage-Object-Detection/</a></span></div><div class="post-copyright-notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://libanghuai.com">Out of Memory</a>！</span></div></div></article><div id="pagination"><div class="prev-post pull-left"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="../../15/Object-as-Distribution/"><i class="fas fa-angle-left">&nbsp;</i><span>Object as Distribution</span></a></div><div class="next-post pull-right"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="../../03/Focal-Loss-for-Dense-Object-Detection/"><span>Focal Loss for Dense Object Detection</span><span>&nbsp;</span><i class="fas fa-angle-right"></i></a></div></div><!--div!= paginator()--></div></div><div class="button-hover" id="return-top"><i class="fas fa-arrow-up" aria-hidden="true"></i></div><footer><div id="footer"><div class="button-hover" id="side-button"><i class="fas fa-arrow-right"></i></div><div class="right-content"><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fas fa-file-o"></i></span><span id="busuanzi_value_page_pv"></span><span></span></div><div class="copyright">&copy;2017 ～ 2020 By Out of Memory</div></div></div></footer></div><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/thirdparty/jquery-3.3.1.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/thirdparty/velocity.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/thirdparty/jquery.mCustomScrollbar.concat.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/fan.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/canvas_bg.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/utils.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/scroll.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/sidebar.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/copy.js"></script><!--script(src=url)--></body></html>