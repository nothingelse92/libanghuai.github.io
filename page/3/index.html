<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>Out of Memory</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Live and Learn">
<meta property="og:type" content="website">
<meta property="og:title" content="Out of Memory">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="Out of Memory">
<meta property="og:description" content="Live and Learn">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Out of Memory">
<meta name="twitter:description" content="Live and Learn">
  
    <link rel="alternate" href="/atom.xml" title="Out of Memory" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Out of Memory</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Live and Learn</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Unconstrained-Face-Alignment-without-Face-Detection" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/19/Unconstrained-Face-Alignment-without-Face-Detection/" class="article-date">
  <time datetime="2018-11-19T15:03:54.000Z" itemprop="datePublished">2018-11-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/19/Unconstrained-Face-Alignment-without-Face-Detection/">Unconstrained Face Alignment without Face Detection</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>URL: <a href="https://ieeexplore.ieee.org/document/8014992" target="_blank" rel="noopener">https://ieeexplore.ieee.org/document/8014992</a><br><strong>【Summary】</strong> CVPR2017 Workshop一篇关于人脸关键点检测的论文，应该主要是在参加CVPR2017的一个Menpo Challenge。  整篇论文的主要内容可以理解为把OpenPose中的一些做法应用到人脸关键点定位任务中。<br>下图是论文中给出的对所提方法整个pipeline的示意，论文所提方法主要可以分成两个部分Basic Landmark Prediction Stage（BLPS）和 Whole Landmark Regression Stage（WLRS）。第一部分负责得到人脸关键点的粗定位（其实只是所有关键点中几个主要的点比如眼球、鼻尖等），第二部分负责在第一阶段的基础上进行进一步的refine：<br><img src="Unconstrained-Face-Alignment-without-Face-Detection-7294485d9c10d1d220cb3c0ea2039e4fefcb135d_1_690x370.jpg" alt></p>
<ul>
<li><strong>Basic Landmark Prediction Stage</strong>：这一部分可以直接理解为OpenPose 中PAF在人脸关键点中的应用。具体细节可以直接参考OpenPose那篇文章。只是在本论文中当前阶段只处理人脸关键点中主要的几个点（左右眼球、鼻尖和左右嘴角共5个点）。<br><img src="Unconstrained-Face-Alignment-without-Face-Detection-216534462f9c38b34a4971687f33a92855b698a9_1_584x499.jpg" alt></li>
<li><strong>Whole Landmark Regression Stage</strong>：这一部分是直接接在BLPS之后进行的。首先会利用BLPS的结果根据关键点的可见性判断人脸的Pose，总共分成三类：left profile、right profile、semi-frontal。那么论文本身是对这三种pose计算过模版脸的，所以可以直接align 到模版脸上，最后直接送到回归网络回归最后的精确结果。感觉这也是目前人脸关键点任务中比较常用的方法：\<br><img src="Unconstrained-Face-Alignment-without-Face-Detection-167f3b8032a6d164916e82241af84a4a205b6060_1_678x500.png" alt></li>
</ul>
<p>论文用的训练数据来自300W + Menpo + CelebA，作者在300W数据集上做的实验结果：</p>
<p><img src="Unconstrained-Face-Alignment-without-Face-Detection-8c807a07df3ad3b1446d8e2ac598ae0448a0eea0.png" alt></p>
<p>这篇论文可以理解为OpenPose方法在人脸关键点定位任务上的直接应用，从方法整体的pipeline上看其实和目前我们在做的landmark定位逻辑是一致的，都是先给部分点的位置然后align在精细refine所有的点。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/19/Unconstrained-Face-Alignment-without-Face-Detection/" data-id="ck337q4i5005c1cfyvn2y5ach" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Face/">Face</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Landmark/">Landmark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Squeeze-and-Excitation-Networks" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/15/Squeeze-and-Excitation-Networks/" class="article-date">
  <time datetime="2018-11-14T17:03:20.000Z" itemprop="datePublished">2018-11-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/15/Squeeze-and-Excitation-Networks/">Squeeze-and-Excitation Networks</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>URL:<a href="https://arxiv.org/abs/1709.01507" target="_blank" rel="noopener">https://arxiv.org/abs/1709.01507</a> Github:<a href="https://github.com/hujie-frank/SENet" target="_blank" rel="noopener">https://github.com/hujie-frank/SENet</a><br>CVPR2017的一篇论文，CNN网络卷积操作本身是整合空间信息和channel信息的，论文作者的motivation是显式地对channel做attention来提高模型的表达能力，论文主要的内容就是一个SE Block：<br><img src="Squeeze-and-Excitation-Networks-image002.png" alt><br>SE Block主要分成两个部分：</p>
<ol>
<li>Squeeze：上图中的Fsq, 本质就是一个Global Average Pooling，将H x W x C映射成1x1xC：<br><img src="Squeeze-and-Excitation-Networks-image003.png" alt></li>
<li>Excitation：上图中的Fex, 本质就是两个全连接层来学习channel的权重信息，W1是第一层FC参数，输出为C/r，W2为第二层FC参数，输出恢复到C，r为压缩比例，用来减少参数量：<br><img src="Squeeze-and-Excitation-Networks-image004.png" alt><br>最后将excitation得到的输出施加到对应的channel上就可以得到最终的输出（图中的Fscale）<br>SE Block本身的设计是一个嵌入模块，所以它可以方便的结合现有的网络结构，论文中给了两个示例SE-Inception和SE-ResNet：<br><img src="Squeeze-and-Excitation-Networks-image005.png" alt><br><img src="Squeeze-and-Excitation-Networks-image006.png" alt><br>论文中还重点论述了SE Block不会对原模型带来比较大的复杂度，对于输入图片大小为224x224时，ResNet50约3.86GFLOPS，SE-ResNet-50约3.87GFLOPS，实际运行时间两者差别也不是很大，贴一张具体的数据：<br><img src="Squeeze-and-Excitation-Networks-image007.png" alt></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/15/Squeeze-and-Excitation-Networks/" data-id="ck337q4hz004x1cfyl1gpl38v" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Detection/">Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Face-R-CNN" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/14/Face-R-CNN/" class="article-date">
  <time datetime="2018-11-14T15:40:24.000Z" itemprop="datePublished">2018-11-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/14/Face-R-CNN/">Face R-CNN</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>URL:<a href="https://arxiv.org/abs/1706.01061" target="_blank" rel="noopener">https://arxiv.org/abs/1706.01061</a><br>腾讯AI Lab发表在CVPR2017上面的论文，在2017年可以做到FDDB 和 Wider Face数据集上面的最好结果，Face R-CNN是基于Faster R-CNN框架的模型，基本结构论文给出了比较详细的示意图：<br><img src="Face-R-CNN-image002.png" alt><br>模型主要有以下几个关键点：</p>
<ol>
<li>Center Loss：论文直接把人脸识别中的center loss沿用到人脸检测中来，出发点还是一样利用Softmax Loss来扩大类间差异，利用Center Loss来减小类间差异，以此来增强模型的鲁棒性，只是在人脸检测中类别总数只有2，人脸和非人脸。<br><img src="Face-R-CNN-image003.png" alt><br>因此模型最终的Loss就变成了cls loss + reg loss + center loss：<br><img src="Face-R-CNN-image004.png" alt></li>
<li>OHEM：利用标准的OHEM做法，以loss作为key排序取Top N作为hard example，作者特别说明使用Center Loss可以有效的控制hard example中的postive和negative的样本数。在最后实现的时候是分别在postive和negative样本上应用OHEM并且控制每个batch两者的比例为1:1.</li>
<li>Multi-Scale Training：这一步其实就是把图片resize成不同的大小进行训练来覆盖不同分辨率……<br>最后实验的结果：<br><img src="Face-R-CNN-image005.png" alt><br>论文整体感觉更偏工程化，通过不断尝试融合现有的方法提高模型在数据集上的表现，没有很特别的地方。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/14/Face-R-CNN/" data-id="ck337q4f9001t1cfygvzrd5c2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Detection/">Detection</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Face/">Face</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Associative-Embedding-End-to-End-Learning-for-Joint-Detection-and-Grouping" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/28/Associative-Embedding-End-to-End-Learning-for-Joint-Detection-and-Grouping/" class="article-date">
  <time datetime="2018-10-28T15:03:29.000Z" itemprop="datePublished">2018-10-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/28/Associative-Embedding-End-to-End-Learning-for-Joint-Detection-and-Grouping/">Associative Embedding: End-to-End Learning for Joint Detection and Grouping</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>URL:<a href="https://papers.nips.cc/paper/6822-associative-embedding-end-to-end-learning-for-joint-detection-and-grouping.pdf" target="_blank" rel="noopener">https://papers.nips.cc/paper/6822-associative-embedding-end-to-end-learning-for-joint-detection-and-grouping.pdf</a><br><strong>【Summary】</strong> Pose estimation 任务中另一个典型的bottom up模型，论文的motivation感觉比OpenPose的PAF更加直观易懂，就是为每一个joint学习一个tag用来标记一组joint。然后再用贪心的逻辑来做group。</p>
<p>下图是论文中给出的整个方法的Pipeline，整个网络总共有两个分支，一个输出关键点位置的heatmap，文中称之为detection，另一个分支就是本文的核心associative embedding，论文中称之为grouping：<br><img src="Associative-Embedding-End-to-End-Learning-for-Joint-Detection-and-Grouping-3c5dd349b51723e15a8ec5ea15463e029db0fb03_1_690x338.jpg" alt><br>至于论文中用到的backbone网络是比较常见的hourglass：<br><img src="Associative-Embedding-End-to-End-Learning-for-Joint-Detection-and-Grouping-e180bb474a3cf204c9540778d188a8f57ffa2ef0.png" alt><br><strong>Associative Embedding</strong><br>论文中提及的embedding可以理解为对人物个体的标记，和NLP中的word embedding一样，embedding的维度其实可以是任意的，本论文中作者通过实践觉得1维的embedding 就足够了，所以对于detection的每一个channel在grouping中都一个同样大小的channel与之对应。<br>在网络训练的时候Detection Loss就是普通的MSE而Grouping Loss是如下设计的：<br><img src="Associative-Embedding-End-to-End-Learning-for-Joint-Detection-and-Grouping-3d23af6063c886a039dec53aa3ac965505139a8c.png" alt><br>其中：<br><img src="Associative-Embedding-End-to-End-Learning-for-Joint-Detection-and-Grouping-2193d834631344a19a46cd6ac97a7346f44364b4.png" alt><br>hk是grouping中一个输出的channel，x为具体的位置，这主要涉及到论文中的reference embedding，reference embedding就是一个人物个体所有joint 在grouping中输出的均值作为对这个人物个体的表示。而在具体的Loss函数中前半段就是把输入同一个人物个体的joint尽量拉近，而公式的后半段就是把不同的人物个体相互拉开。<br>具体Inference的时候通过某一个joint的heatmap的峰值来确定检测到的人的pool，然后再依次去利用其他joint的tag来和这个pool里面的人进行match。如果当前这个joint无法和pool里面的任意一个人match，那么就会作为单独的一个人加入到这个pool，然后一直进行这样的贪心流程。</p>
<p>作者在COCO和MPII数据集上分别做了测试，从结果上来看点还是比较高的：<br><img src="Associative-Embedding-End-to-End-Learning-for-Joint-Detection-and-Grouping-8c807a07df3ad3b1446d8e2ac598ae0448a0eea0.png" alt></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/10/28/Associative-Embedding-End-to-End-Learning-for-Joint-Detection-and-Grouping/" data-id="ck337q4d7000m1cfy70w0ncno" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BottomUp/">BottomUp</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/KeyPoint/">KeyPoint</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Landmark/">Landmark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-SNIPER-Efficient-Multi-Scale-Training" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/22/SNIPER-Efficient-Multi-Scale-Training/" class="article-date">
  <time datetime="2018-10-22T14:43:00.000Z" itemprop="datePublished">2018-10-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/22/SNIPER-Efficient-Multi-Scale-Training/">SNIPER: Efficient Multi-Scale Training</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>URL: <a href="https://arxiv.org/abs/1805.09300" target="_blank" rel="noopener">https://arxiv.org/abs/1805.09300</a> Github: <a href="https://github.com/MahyarNajibi/SNIPER" target="_blank" rel="noopener">https://github.com/MahyarNajibi/SNIPER</a><br><strong>【Summary】</strong>算是在SNIP版本上的改进吧，主要想优化multi scale训练的效率问题。论文提出了chip的概念，其实就是原图中的某一块区域，在本论文中chip的大小就是512 x 512的矩形方块。网络的输入不再是原图，而是这些生成的chip。SNIPER的主要内容就是这些chip的生成逻辑。</p>
<p>作为网络的输入，chip也分为postive chip和negative chip, 下图是postive chip的生成示例。对于给定的一张图，会有512 x 512这样大小的chip框在原图上滑动，间隔为32个pixel。包含valid gt（valid或者invalid的定义和SNIP那篇论文逻辑一样）的chip被称为postive chip。由于对于给定的一张图片不会把每一个chip都送给网络去训练，所以通常都是贪心的选择包含valid gt最多的chip作为这张图的postive chip：</p>
<p><img src="SNIPER-Efficient-Multi-Scale-Training-2feaec373ba84ada0c26428b063370d8588e35d8_1_690x386.jpg" alt><br>下面这张图则是negative chip的生成示例，论文中作者生成的negative chip是想包含那些比较难解的FP，所以作者用了一个简单的RPN网络来生成negative chip，下图的红点代表一个proposal（已经移除掉被postive chip包含的那些了）。negative chip被定义为至少含M个proposal的那些chip(论文中M貌似没给出具体的值)：</p>
<p><img src="SNIPER-Efficient-Multi-Scale-Training-54af81d1f0fbbac701cb898fe22e2ee48d188efe_1_690x341.png" alt><br>贴一张实验结果：</p>
<p><img src="SNIPER-Efficient-Multi-Scale-Training-6bcbdd2062f585821204274dfe18fd845f2a4544_1_690x316.png" alt></p>
<p>感觉这篇论文的重点用论文中的一句话可以很好的概括”it implies that very large context during training is not important for training high-performance detectors but sampling regions containing hard negatives is”</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/10/22/SNIPER-Efficient-Multi-Scale-Training/" data-id="ck337q4hv004n1cfyyqhehuhq" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Detection/">Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-RMPE-Regional-Multi-Person-Pose-Estimation" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/14/RMPE-Regional-Multi-Person-Pose-Estimation/" class="article-date">
  <time datetime="2018-10-14T15:03:01.000Z" itemprop="datePublished">2018-10-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/14/RMPE-Regional-Multi-Person-Pose-Estimation/">RMPE: Regional Multi-Person Pose Estimation</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>URL: <a href="https://arxiv.org/abs/1612.00137" target="_blank" rel="noopener">https://arxiv.org/abs/1612.00137</a><br><strong>【Summary】</strong>ICCV2017关于Pose Estimation的论文，主要是基于目前Top Down方法的改进。论文主要想解决一个问题，就是Top Down方法中human detector出的框不准或者比较冗余的问题。STN来映射更准的框， Pose NMS 来更好的解决冗余框的问题。</p>
<p>下图是论文中给出的对于RMPE方法的简单示例，整个Pipeline针对human detector出框不准或者比较冗余的问题分别进行了针对性的设计，下图中的前半段STN + SPPE + SDTN主要用于fix human detector出框不准的问题，后半段的Pose NMS主要用来解决冗余的问题：</p>
<p><img src="RMPE-Regional-Multi-Person-Pose-Estimation-40073134aa3c4bacc77a9e9fda9a039e18627b2a_1_690x253.jpg" alt></p>
<ul>
<li><strong>SPPE的改进：</strong> SPPE（Single Person Pose Estimation）主要改进的地方就是引入STN和SDTN来实现更加精确的pose estimation。细节上STN接受human detector输出的proposal（具体实现的时候会在原有的proposal基础上，长宽各扩展30%以保证覆盖全部的人体区域），STN生成的仿射变换矩阵将当前的proposal映射的更加精确，然后再输入SPPE网络中（实际实验时是4-stack hourglass结构）得到具体的joint的位置，然后通过STN的逆变换SDTN得到原始的坐标位置。下图中的Parallel SPPE作用是对STN进行进一步的监督，监督的Label是已经center-located的pose，所以当然也就不需要SDTN这一步了。从下图中也可以比较直观的看出来，上下两个branch label还是不一样的，为了映射回原坐标，上半分支的SDTN是必要的：<br><img src="RMPE-Regional-Multi-Person-Pose-Estimation-bba38f5d3a2f3183198d1b3e1edad64fdf69cf6d_1_690x253.jpg" alt></li>
<li><strong>Pose NMS：</strong> 对于Pose NMS作者主要在研究一件事就是如何来定义Pose 的冗余以及消除冗余的标准，就像物体检测的NMS用IoU和confidence的逻辑一样。论文中作者用如下的方式来定义：<br><img src="RMPE-Regional-Multi-Person-Pose-Estimation-0dfc09cf7e37b3b1ca4ff52221f214f16ba73bb4.png" alt><br>其中，H<sub>Sim</sub>用来建模距离上的相似度，K<sub>Sim</sub>用来建模confidence之间的关系，B(K<sub>i</sub><sup>n</sup>)代表1以K<sub>i</sub><sup>n</sup>为中心的矩形，矩形大小为这个Pose对应框的1/10：<br><img src="RMPE-Regional-Multi-Person-Pose-Estimation-f21a4f8fbd194882b2ffb4506b29dfeda3696354.png" alt><br><img src="RMPE-Regional-Multi-Person-Pose-Estimation-144986445bc91b1f0003ee01a3ce41c772544bdb.png" alt></li>
<li>此外作者也针对所提的RMPE结构设计了Data Augmentation方法，主要是根据原子pose进行聚类，然后对于输入的图像首先对其进行分类，然后利用对应的offset分布构造一组新的数据，具体的分布信息：<br><img src="RMPE-Regional-Multi-Person-Pose-Estimation-36ee4b370f48e74a1f0f269815e6d4c9db9a7d06.jpg" alt><br>在MPII数据集上的表现：<br><img src="RMPE-Regional-Multi-Person-Pose-Estimation-70e6ebcbc5feaad8636963960565eb32feae49aa_1_690x250.png" alt><br>在COCO Chanllenge上的表现：<br><img src="RMPE-Regional-Multi-Person-Pose-Estimation-4b243ddf5903093632852b6f2830838278676f40.png" alt></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/10/14/RMPE-Regional-Multi-Person-Pose-Estimation/" data-id="ck337q4hb003q1cfyksfyuy8q" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Bottom-UP/">Bottom UP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/KeyPoint/">KeyPoint</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Landmark/">Landmark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Pelee-A-Real-Time-Object-Detection-System-on-Mobile-Devices" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/25/Pelee-A-Real-Time-Object-Detection-System-on-Mobile-Devices/" class="article-date">
  <time datetime="2018-09-25T12:05:00.000Z" itemprop="datePublished">2018-09-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Paper-Reading/">Paper Reading</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/25/Pelee-A-Real-Time-Object-Detection-System-on-Mobile-Devices/">Pelee: A Real-Time Object Detection System on Mobile Devices</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这篇论文主要做的内容是在手机终端上进行实时的物体检测并提出了PeleeNet模型，不同于目前的MobileNet、ShuffleNet等基于 depthwise separable convolution的模型，<br>PeleeNet是基于传统的卷积来实现的，因为作者认为depthwise separable convolution操作在诸多的框架下都没有有效的支持……<br>论文主要借鉴了DenseNet、DSOD、Inception-V4等现有的网络，模型结构在论文中给出了比较详细的列表，几个需要注意的细节：</p>
<ol>
<li>作者参考GoogleNet在DenseBlock中引入2-way dense layer来获得不同大小的感受野。<br><img src="Pelee-A-Real-Time-Object-Detection-System-on-Mobile-Devices/image004.png" alt="Pelee"></li>
<li>DenseNet中表现较好的DenseNet-BC结构是在原有的基本DenseNet结构基础上加入了Bottleneck和Compression，但是作者认为compression逻辑的加入影响模型的特征表达，<br>所以下表中的Transition Layer没有compression的逻辑，输入输出channel数保持一致。<br><img src="Pelee-A-Real-Time-Object-Detection-System-on-Mobile-Devices/image002.png" alt="Pelee"></li>
<li>Composite Function中用Post-activation替换掉DenseNet中的Pre-activation，以此来在inference阶段加速计算。</li>
<li>用Bottleneck Layer控制输出的channel数不大于输入的channel数，此操作除了可以节省28.5%的计算量，对准确率的影响也比较小。<br><img src="Pelee-A-Real-Time-Object-Detection-System-on-Mobile-Devices/image003.png" alt="Pelee"></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/25/Pelee-A-Real-Time-Object-Detection-System-on-Mobile-Devices/" data-id="ck337q4h2003c1cfy0x042m35" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Detection/">Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Cascade-R-CNN-Delving-into-High-Quality-Object-Detection" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/24/Cascade-R-CNN-Delving-into-High-Quality-Object-Detection/" class="article-date">
  <time datetime="2018-09-24T10:16:03.000Z" itemprop="datePublished">2018-09-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/24/Cascade-R-CNN-Delving-into-High-Quality-Object-Detection/">Cascade R-CNN: Delving into High Quality Object Detection</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>解决问题：<br>目前的检测模型通常需要通过设置IoU阈值来定义Positive和Negative bbox，作者发现<br>最终检测模型的表现和IoU阈值的设置相关，通过下图的c，d可以发现低IoU阈值通常<br>会对低IoU样本表现更好，因为不同IoU阈值下的样本分布不一样，一个IoU阈值很难对<br>所有的样本都有效。因此为了解决这个问题，论文提出了Cascade R-CNN 模型。<br><img src="Cascade-R-CNN-Delving-into-High-Quality-Object-Detection/image002.png" alt="Cascade R-CNN"><br>论文实验的Cascade R-CNN模型基于典型的Two-Stage结构，Cascade R-CNN模型有多个<br>Classification和Bounding Box header（下图中的Cx，Bx），前一个header refine过的Bounding Box 会作为下一个header的输入，并且IoU的阈值逐层增加，B0代表RPN的结果。<br>通过这种方式实现对于每一级header输入数据的resample，保证了每一级header都有足够的正样本。<br><img src="Cascade-R-CNN-Delving-into-High-Quality-Object-Detection/image003.png" alt="Cascade R-CNN"><br>实验对比，可以发现cascade rcnn的效果还是有比较大的提升，但同时也大幅大增加了模型的复杂度</p>
<p><img src="Cascade-R-CNN-Delving-into-High-Quality-Object-Detection/image004.png" alt="Cascade R-CNN"></p>
<p>思考：<br>Cascade R-CNN结构是现有检测模型优化的思考方向，但是从上图第二章表中也可以看出加入<br>cascade 结构在提高检测效果的同时也大幅度增加了模型复杂度，对于目前的手机平台这还是挺不利的，<br>下周会具体实验。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/24/Cascade-R-CNN-Delving-into-High-Quality-Object-Detection/" data-id="ck337q4e200181cfyk75r3enw" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Single-Shot-Refinement-Neural-Network-for-Object-Detection" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/24/Single-Shot-Refinement-Neural-Network-for-Object-Detection/" class="article-date">
  <time datetime="2018-09-24T10:10:10.000Z" itemprop="datePublished">2018-09-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/24/Single-Shot-Refinement-Neural-Network-for-Object-Detection/">Single-Shot Refinement Neural Network for Object Detection</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>论文致力于研究整合two-stage检测器和one-stage检测器的优点提出了RefineDet网络结构。<br><img src="Single-Shot-Refinement-Neural-Network-for-Object-Detection/image003.png" alt="RefineDet"><br>网络结构整体借鉴了SSD模型并结合了cascade逻辑，整个网络主要分成三个部分：</p>
<ol>
<li>Anchor  Refinement Module（ARM）：这一模块的模型结构和SSD比较类似，不同的是它只做二分类，ARM对anchor进行初步的refine并得到相对粗糙的位置信息和分类信息，这一部分信息将作为ODM模块的输入。<br>特别的，为了缓解类别失衡问题，论文提出了Negative Anchor过滤逻辑，将negative confidence大于某一个阈值（如0.95）的anchor全部舍弃掉不送入ODM模块。</li>
<li>Object Detection Module (ODM): 这一模块的结构和ARM类似，并且两者对应layer的size是一致的，论文中给出的结构图例比较直观。ODM模块主要是借助ARM模块refine过后的anchor进行进一步细致的处理并最终输出物体的类别信息和bounding box的位置信息。在具体实现的时候，ARM和ODM之间采用了类似FPN特征融合的方法将ARM高层的feature map与低层的feature map相融合并与ODM对应layer的feature map一同作为下一层layer的输入，以此来提高检测的效果。</li>
<li>Transfer Connection Block (TCB)：TCB主要用来融合低层和高层feature map，论文给的图示比较清楚主要就是对高层feature map进行deconv并与低层feature map相加；<br><img src="Single-Shot-Refinement-Neural-Network-for-Object-Detection/image002.png" alt="RefineDet"><br>实验结果：<br><img src="Single-Shot-Refinement-Neural-Network-for-Object-Detection/image004.png" alt="RefineDet"></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/24/Single-Shot-Refinement-Neural-Network-for-Object-Detection/" data-id="ck337q4i0004z1cfy8mmwhffb" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Detection/">Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-CoupleNet-Coupling-Global-Structure-with-Local-Parts-for-Object-Detection" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/24/CoupleNet-Coupling-Global-Structure-with-Local-Parts-for-Object-Detection/" class="article-date">
  <time datetime="2018-09-24T10:05:22.000Z" itemprop="datePublished">2018-09-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/24/CoupleNet-Coupling-Global-Structure-with-Local-Parts-for-Object-Detection/">CoupleNet: Coupling Global Structure with Local Parts for Object Detection</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>R-FCN将RoI划分成区域通过整合各个区域的信息来表征最后的结果，而CoupleNet的motivation是利用R-FCN中对局部信息的学习能力再整合全局和context信息来提升模型的检测效果。<br><img src="CoupleNet-Coupling-Global-Structure-with-Local-Parts-for-Object-Detection/image002.png" alt="CoupleNet"><br>CoupleNet网络主要分成两个分支：</p>
<ol>
<li>Local FCN：引入R-FCN中的Position-sensitive score maps 和 Position-sensitive RoI pooling 得到局部信息给出的结果，对于分类会输出C+1维的特征向量，具体细节直接参考R-FCN即可。</li>
<li>Global FCN：这个分支主要用来整合RoI的全局信息和context信息，上图中的两个RoI Pooling就是分别来映射这部分特征的，第一部分是全局的特征信息，第二部分是在第一部分RoI的基础上范围向外扩大2倍再进心RoI Pooling这样可以引入部分的context信息来增强特征提高检测的效果，最后两者feature map直接concat到一起经过kxk和1x1两个卷积层之后同样得到C+1维的特征向量</li>
<li>Coupling structure：两个分支输出的整合作者也做了很多的实验，(L2 normalization layer , 1x1 conv layer)  x (element-wise max, element-wise product, element-wise sum) 共6种组合中1x1 conv + element-wise sum 表现最好。</li>
</ol>
<p>实验结果，速度方面因为CoupleNet相当于在R-FCN的基础上引入了Global FCN的分支，所以很显然速度要慢于R-FCN的，但还是明显快于faster rcnn的，检测效果方面效果也很好。<br><img src="CoupleNet-Coupling-Global-Structure-with-Local-Parts-for-Object-Detection/image003.png" alt="CoupleNet"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/24/CoupleNet-Coupling-Global-Structure-with-Local-Parts-for-Object-Detection/" data-id="ck337q4e6001b1cfyens7g7m6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Detection/">Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-DSOD-Learning-Deeply-Supervised-Object-Detectors-from-Scratch" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/21/DSOD-Learning-Deeply-Supervised-Object-Detectors-from-Scratch/" class="article-date">
  <time datetime="2018-09-21T10:20:04.000Z" itemprop="datePublished">2018-09-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/21/DSOD-Learning-Deeply-Supervised-Object-Detectors-from-Scratch/">DSOD: Learning Deeply Supervised Object Detectors from Scratch</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>论文主要想解决的问题是如何直接去训练一个detection模型，因为现在detection模型都是利用ImageNet数据预训练的，灵活性相对较差，分类和检测的场景也不一致，因此论文提出了DSOD模型。<br>论文中提出的DSOD模型结构通过下表可以直观的看到，Stem、Dense Block、Transition Layer都是参考现有的研究成果，论文主要的贡献是<br> Transition w/o Pooling Layer 和 Dense Prediction Structure：</p>
<ol>
<li>Transition w/o Pooling Layer：这个结构主要用来实现增加Densen Block模块个数的同时保持输出的size不变，从表中可以直观的看到其实就是1x1的卷积，<br>因为传统densenet中的transition layer会利用pooling层来对feature map下采样，这里用Transition w/o Pooling Layer来保持输出的size与transition layer区分开。<br><img src="DSOD-Learning-Deeply-Supervised-Object-Detectors-from-Scratch/image002.png" alt="DSOD"></li>
<li>Dense Prediction Structure：论文中用下图来解释Dense Prediction Structure，和常用的结构（左侧）相比较主要的差别在于 Learning Half and Reusing Half，<br>每一层网络的输入都是上一层的输出feature map 和 前面层的下采样结果的concatenate，因此对于每一层的输出一半是通过学习得到的另一半则是直接从前面层<br>下采样得到的，这样可以直接复用前面的信息。</li>
</ol>
<p><img src="DSOD-Learning-Deeply-Supervised-Object-Detectors-from-Scratch/image003.png" alt="DSOD"><br>具体的实验结果，或许看完这篇文章最好奇的是从头训练的检测模型和预训练过的检测模型具体效果的好坏，论文的最后作者利用<br> DS/64-12-16-1做了比较，发现从头训练的模型效果要好于预训练过的模型（70.7% vs 70.3%）</p>
<p><img src="DSOD-Learning-Deeply-Supervised-Object-Detectors-from-Scratch/image004.png" alt="DSOD"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/21/DSOD-Learning-Deeply-Supervised-Object-Detectors-from-Scratch/" data-id="ck337q4eb001e1cfy2wsi07k2" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-R-FCN-Object-Detection-via-Region-based-Fully-Convolutional-Networks" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/01/R-FCN-Object-Detection-via-Region-based-Fully-Convolutional-Networks/" class="article-date">
  <time datetime="2018-09-01T09:21:35.000Z" itemprop="datePublished">2018-09-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/01/R-FCN-Object-Detection-via-Region-based-Fully-Convolutional-Networks/">R-FCN: Object Detection via Region-based Fully Convolutional Networks</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>URL:<a href="https://arxiv.org/abs/1605.06409" target="_blank" rel="noopener">https://arxiv.org/abs/1605.06409</a> Github:<a href="https://github.com/daijifeng001/r-fcn" target="_blank" rel="noopener">https://github.com/daijifeng001/r-fcn</a><br>R-FCN网络设计的motivation是为了增强物体检测网络位置敏感性，提高物体检测的精度和速度。它的整体结构是一个two stage的网络，RPN网络分支生成Proposal Candidate RoIs ，另一个分支基于此做进一步的refine。<br><img src="R-FCN: Object Detection via Region-based Fully Convolutional Networks/image002.png" alt="R-FCN"><br>R-FCN网络结构设计的核心是Position-sensitive score maps 和Position-sensitive RoI pooling ：</p>
<ol>
<li>Position-sensitive score maps：不妨假设RoI的大小为wxh，那么将RoI均分成k x k个区域，那么每个区域的大小就约为w/k x h/k，对于C分类任务，最后的输出就有kxkx(C+1)个channel，用来表征各个区域的分类信息。而对于候选框的位置，最后的输出是4xkxk个channel。<br><img src="R-FCN: Object Detection via Region-based Fully Convolutional Networks/image003.png" alt="R-FCN Details"></li>
<li>Position-sensitive RoI pooling：这一部分主要用来整合Position-sensitive score maps的信息得到最终的结果，Pooling公式中的i，j代表kxk个bin的id信息，c为C个类别中的一个，x0，y0为区域的左上角坐标，那么实际上在整个论文中用的是average pooling，作者也提到max pooling也是可以的。<br><img src="R-FCN: Object Detection via Region-based Fully Convolutional Networks/image004.png" alt="R-FCN gongshi"><br>所以经过Position-sensitive RoI pooling之后输出为kxkx(C + 1), 对于每一个类别c最后的打分是kxk个值的均值，因此最后的输出变成C+1维的向量，最后通过softmax得到最后的分类结果。对于bbox框位置的回归也和分类类似，只是channel数是4xkxk，最后得到4维的向量作为位置信息的偏移量。</li>
<li>实验结果，速度相比较faster rcnn还是有比较明显的提升，检测效果也不错。<br><img src="R-FCN: Object Detection via Region-based Fully Convolutional Networks/image005.png" alt="R-FCN gongshi"><br>R-FCN网络的设计有一个特点，在得到score maps之后Position-sensitive RoI pooling没有引进其他的参数，无疑有助于train和inference的速度，通过划分区域人为的对位置做细分也有实际的意义，但是个人对regression阶段也用同样的操作不是很理解..</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/01/R-FCN-Object-Detection-via-Region-based-Fully-Convolutional-Networks/" data-id="ck337q4h9003n1cfy6tarxrrt" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Detection/">Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Inception-Series" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/30/Inception-Series/" class="article-date">
  <time datetime="2018-07-30T14:57:52.000Z" itemprop="datePublished">2018-07-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/30/Inception-Series/">Inception Series</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/30/Inception-Series/" data-id="ck337q4gm002l1cfydjlm5j3w" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-UnitBox-An-Advanced-Object-Detection-Network" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/22/UnitBox-An-Advanced-Object-Detection-Network/" class="article-date">
  <time datetime="2018-07-22T15:50:29.000Z" itemprop="datePublished">2018-07-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Paper-Reading/">Paper Reading</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/22/UnitBox-An-Advanced-Object-Detection-Network/">UnitBox: An Advanced Object Detection Network</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>You can find this paper <a href="https://arxiv.org/pdf/1608.01471.pdf" target="_blank" rel="noopener">here</a></p>
<h1 id="Two-Main-Contributions"><a href="#Two-Main-Contributions" class="headerlink" title="Two Main Contributions:"></a>Two Main Contributions:</h1><h2 id="IoU-Loss"><a href="#IoU-Loss" class="headerlink" title="- IoU Loss"></a>- <strong>IoU Loss</strong></h2><p>在目前的神经网络训练中，L2 Loss是比较常用的Loss函数，它其实就是欧式距离的计算，L2 Loss有两个比较典型的缺点：</p>
<ol>
<li>在L2 Loss中，Bounding Box的四个角被看作相互独立的单元，计算Loss的时候都是分别去优化左上角的坐标和Bounding Box的长、宽，但是实际上在检测问题中一个物体的边界是高度相关的。忽略其中的联系也会导致一些badcase，比如预测的Bounding Box可能有一、两条边和Ground Truth的很接近但是整个预测的Bounding Box偏离的比较离谱。</li>
<li>标准的L2 Loss是没有normalize的, 那么在训练过程中模型就会更加关注大一点的Bounding Box，当然现在也有了很多normalize的方法被提出来。</li>
</ol>
<p>基于此，论文作者提出了IoU Loss：<br><img src="UnitBox-An-Advanced-Object-Detection-Network/IoU_Loss.png" alt="IoU Loss"></p>
<h2 id="UnitBox-Network-Structure"><a href="#UnitBox-Network-Structure" class="headerlink" title="- UnitBox Network Structure"></a>- UnitBox Network Structure</h2><p><img src="UnitBox-An-Advanced-Object-Detection-Network/UnitBox.png" alt="IoU Loss"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/22/UnitBox-An-Advanced-Object-Detection-Network/" data-id="ck337q4i400591cfy4ra3gze4" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Detection/">Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Quick-Sort" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/20/Quick-Sort/" class="article-date">
  <time datetime="2018-07-20T14:45:34.000Z" itemprop="datePublished">2018-07-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Algorithm/">Algorithm</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/20/Quick-Sort/">Quick Sort</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/20/Quick-Sort/" data-id="ck337q4hc003s1cfy730jm21b" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Template/">Template</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Build-Hadoop-Spark-Cluster" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/20/Build-Hadoop-Spark-Cluster/" class="article-date">
  <time datetime="2018-07-20T14:39:24.000Z" itemprop="datePublished">2018-07-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/20/Build-Hadoop-Spark-Cluster/">Build Hadoop &amp;&amp; Spark Cluster</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>单机配置</p>
<ul>
<li>创建用户和用户组<br>groupadd hadoop//新建用户组<br>useradd hadoop -g hadoop//把用户加入用户组<br>passwd hadoop//为用户hadoop设置密码然后会提示输入密码和确认密码</li>
<li>修改hostname和hosts<br>vim /etc/hostname<br>vim /etc/hosts</li>
<li><p>修改用户权限<br>vim /etc/sudoers</p>
</li>
<li><p>配置无密码登录<br>cd ~/.ssh/     //如果目录下没有这个文件夹，需要执行以下ssh localhost生成这个文件夹<br>ssh-keygen -t rsa //生成key,过程中只管敲回车<br>cat ./id_rsa.pub &gt;&gt; ./authorized_keys //授权, 有时候非root用户授权会失败，就是直接执行ssh localhost还是会提示输入密码，那么多半是文件权限的问题：chmod 600 .ssh/authorized_keys 修改权限即可</p>
</li>
<li>安装Java JDK<br>下载Java JDK: <a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a><br>设置环境变量: vim /etc/profile,在文件最后加入:<br>#Java Env<br>export JAVA_HOME=/usr/local/java/jdk1.8.0_162<br>export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar<br>export PATH=$PATH:$JAVA_HOME/bin<br>使配置生效: source /etc/profile<br>测试java环境:<br>java<br>java -version<br>javac</li>
<li>安装Hadoop<br>下载Hadoop: <a href="http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.6.5/hadoop-2.6.5.tar.gz" target="_blank" rel="noopener">http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.6.5/hadoop-2.6.5.tar.gz</a><br>解压Hadoop到/usr/local/目录下：tar -zxf ~/hadoop-2.6.5.tar.gz -C /usr/local<br>mv hadoop-2.6.5/ hadoop<br>chown -R hadoop ./hadoop/  //设置权限<br>./hadoop/bin/hadoop version //查看hadoop安装包是否完整<br>配置环境变量，vim /etc/profile,在文件的最后加入：<br>export HADOOP_HOME=/usr/local/hadoop<br>export PATH=$HADOOP_HOME/bin:/$HADOOP_HOME/sbin:$PATH</li>
<li>配置Hadoop<ul>
<li>总共配置6个文件: slaves、core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml</li>
<li>slaves: 将作为 DataNode也就是Slave机器的主机名写入该文件，每行一个，默认为 localhost，所以在伪分布式配置时，节点即作为 NameNode 也作为 DataNode。分布式配置可以保留 localhost，也可以删掉，让 Master 节点仅作为 NameNode 使用。 本项目让 Master 节点仅作为 NameNode 使用，因此将文件中原来的 localhost 删除，只添加一行内容：162.105.67.62</li>
<li>hadoop-env.sh：添加Java JDK路径<h1 id="The-java-implementation-to-use"><a href="#The-java-implementation-to-use" class="headerlink" title="The java implementation to use."></a>The java implementation to use.</h1>export JAVA_HOME=/usr/local/java/jdk1.8.0_162</li>
</ul>
</li>
<li>core-site.xml:<configuration><br>  <property><br>      <name>fs.defaultFS</name><br>      <value>hdfs://HadoopMaster:9000</value><br>  </property><br>  <property><br>      <name>hadoop.tmp.dir</name><br>      <value>file:/usr/local/hadoop/tmp</value><br>      <description>Abase for other temporary directories.</description><br>  </property><br></configuration></li>
<li>hdfs-site.xml:dfs.replication 一般设为 3，但我们只有一个 Slave 节点，所以 dfs.replication 的值还是设为 1</li>
</ul>
<configuration><br>        <property><br>                <name>dfs.namenode.secondary.http-address</name><br>                <value>HadoopMaster:50090</value><br>        </property><br>        <property><br>                <name>dfs.replication</name><br>                <value>1</value><br>        </property><br>        <property><br>                <name>dfs.namenode.name.dir</name><br>                <value>file:/usr/local/hadoop/tmp/dfs/name</value><br>        </property><br>        <property><br>                <name>dfs.datanode.data.dir</name><br>                <value>file:/usr/local/hadoop/tmp/dfs/data</value><br>        </property><br></configuration><br><em> mapred-site.xml:需要将mapred-site.xml.template文件重命名<br><configuration><br>        <property><br>                <name>mapreduce.framework.name</name><br>                <value>yarn</value><br>        </property><br>        <property><br>                <name>mapreduce.jobhistory.address</name><br>                <value>HadoopMaster:10020</value><br>        </property><br>        <property><br>                <name>mapreduce.jobhistory.webapp.address</name><br>                <value>HadoopMaster:19888</value><br>        </property><br></configuration>
</em>   yarn-site.xml:<br><configuration><br><br><!-- Site specific YARN configuration properties --><br>    <property><br>                <name>yarn.resourcemanager.hostname</name><br>                <value>HadoopMaster</value><br>        </property><br>        <property><br>                <name>yarn.nodemanager.aux-services</name><br>                <value>mapreduce_shuffle</value><br>        </property><br></configuration>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/20/Build-Hadoop-Spark-Cluster/" data-id="ck337q4dg000t1cfyagyxg6qu" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Build-Jitamin-in-CentOS7" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/19/Build-Jitamin-in-CentOS7/" class="article-date">
  <time datetime="2018-07-19T14:59:30.000Z" itemprop="datePublished">2018-07-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Engineering/">Engineering</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/19/Build-Jitamin-in-CentOS7/">Build Jitamin in CentOS7</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>环境:CentOS7</p>
<ul>
<li><strong>安装相关依赖</strong>：<ul>
<li>安装apache: yum install httpd</li>
<li>安装php 7:<ul>
<li>yum -y install epel-release</li>
<li>rpm -Uvh <a href="https://mirror.webtatic.com/yum/el7/webtatic-release.rpm" target="_blank" rel="noopener">https://mirror.webtatic.com/yum/el7/webtatic-release.rpm</a></li>
<li>yum install php70w</li>
<li>查看PHP是否安装成功: php -v</li>
</ul>
</li>
<li>安装Composer:<ul>
<li>curl -sS <a href="https://getcomposer.org/installer" target="_blank" rel="noopener">https://getcomposer.org/installer</a> | php</li>
<li>mv composer.phar /usr/local/bin/composer</li>
<li>检查composer是否安装成功: composer</li>
</ul>
</li>
<li>安装Mysql:<ul>
<li>wget -i -c <a href="http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm" target="_blank" rel="noopener">http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm</a></li>
<li>yum -y install mysql57-community-release-el7-10.noarch.rpm</li>
<li>yum -y install mysql-community-server</li>
</ul>
</li>
</ul>
</li>
<li><strong>安装Jitamin</strong>:<ul>
<li>cd &lt;安装目录&gt;如：cd /usr/local</li>
<li>下载jitamin: git clone <a href="https://github.com/jitamin/jitamin.git" target="_blank" rel="noopener">https://github.com/jitamin/jitamin.git</a> jitamin</li>
<li>cd jitamin/</li>
<li>cp .env.example .env</li>
<li>配置.env文件:<ul>
<li>修改DB_HOSTNAME,DB_USERNAME等数据库属性</li>
</ul>
</li>
<li>安装相关依赖:composer install -o –no-dev<ul>
<li><font color="#FF4500"><strong>可能会遇到一些problem</strong></font>:<ul>
<li>缺失PHP-gd: yum install php70w-gd</li>
<li>缺失PHP-mbstring: yum install php70w-mbstring</li>
<li>缺失PHP-dom: yum install php70w-dom</li>
</ul>
</li>
</ul>
</li>
<li>创建数据库表: vendor/bin/phinx migrate</li>
<li>安装初始数据: vendor/bin/phinx seed:run</li>
<li>确保bootstrap/cache和storage目录可写:<ul>
<li>chmod -R 0777 bootstrap/cache</li>
<li>chmod -R 0777 storage</li>
</ul>
</li>
<li>同步cache:<ul>
<li>php artisan config:cache</li>
<li>php artisan route:cache</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>配置web服务器</strong>:</p>
<ul>
<li>主要就是配置apache的配置文件</li>
<li>利用yum安装的apache默认配置文件存放于: /etc/httpd/conf/httpd.conf</li>
<li>我们要做的就是在/etc/httpd/conf.d目录下新建jitamin.conf内容如下:<pre><code>&lt;VirtualHost *:80&gt;
DocumentRoot &quot;/usr/local/jitamin/public&quot;
DirectoryIndex index.php
&lt;Directory &quot;/usr/local/jitamin/public&quot;&gt;
  AllowOverride all
  Options -Indexes +FollowSymLinks +ExecCGI
  AllowOverride All
  Order allow,deny
  Allow from all
  Require all granted
&lt;/Directory&gt;
&lt;/VirtualHost&gt;
</code></pre><ul>
<li>最后重启apache即可: service httpd restart</li>
</ul>
</li>
</ul>
</li>
<li><p><font color="#FF4500"><strong>可能会遇到的问题</strong></font></p>
<ul>
<li>在创建数据库表和插入数据库数据的时候可能会遇到xxx pdo xxxx相关的问题<ul>
<li>解决方法<ul>
<li>yum install php70w-pdo</li>
<li>yum install php70w-mysql</li>
</ul>
</li>
</ul>
</li>
<li>这个时候访问xxx.xxx.xxx.xxx(主机地址)可能会出现500 internal error的问题，查看log会发现是显示PHP无法连接上mysql<ul>
<li>解决方法<ul>
<li>grant授权，本机配置时是直接grant all到所有的机器上</li>
</ul>
</li>
</ul>
</li>
<li>继续访问还是会出现500的error<ul>
<li>解决方法<ul>
<li>最后发现是selinux的问题</li>
<li>setenforce 0</li>
<li>setsebool httpd_can_network_connect_db=1</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/19/Build-Jitamin-in-CentOS7/" data-id="ck337q4dk000w1cfyq2uiw8rb" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tools/">Tools</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Build-Gitlab-in-CentOS7" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/19/Build-Gitlab-in-CentOS7/" class="article-date">
  <time datetime="2018-07-19T14:56:50.000Z" itemprop="datePublished">2018-07-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Engineering/">Engineering</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/19/Build-Gitlab-in-CentOS7/">Build Gitlab in CentOS7</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="预配置相关环境"><a href="#预配置相关环境" class="headerlink" title="预配置相关环境"></a>预配置相关环境</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install curl policycoreutils openssh-server openssh-clients</span><br><span class="line">sudo systemctl enable sshd</span><br><span class="line">sudo systemctl start sshd</span><br><span class="line">sudo yum install postfix</span><br><span class="line">sudo systemctl enable postfix</span><br><span class="line">sudo systemctl start postfix</span><br><span class="line">sudo firewall-cmd --permanent --add-service=http</span><br><span class="line">sudo systemctl reload firewalld</span><br></pre></td></tr></table></figure>
<h2 id="添加GitLab镜像源并安装"><a href="#添加GitLab镜像源并安装" class="headerlink" title="添加GitLab镜像源并安装"></a>添加GitLab镜像源并安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -sS http://packages.gitlab.com.cn/install/gitlab-ce/script.rpm.sh | sudo bash</span><br><span class="line">sudo yum install gitlab-ce</span><br></pre></td></tr></table></figure>
<p>或者直接从源下载拷贝到服务器上RPM -ivh xxx.rpm 安装: <a href="https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/</a></p>
<h2 id="配置并启动-GitLab"><a href="#配置并启动-GitLab" class="headerlink" title="配置并启动 GitLab"></a>配置并启动 GitLab</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gitlab-ctl reconfigure</span><br></pre></td></tr></table></figure>
<h2 id="可能遇到的问题"><a href="#可能遇到的问题" class="headerlink" title="可能遇到的问题"></a><font color="red">可能遇到的问题</font></h2><ul>
<li>安装GitLab出现ruby_block[supervise_redis_sleep] action run<ul>
<li>按住CTRL+C强制结束</li>
<li>运行：sudo systemctl restart gitlab-runsvdir</li>
<li>再次执行：sudo gitlab-ctl reconfigure</li>
</ul>
</li>
<li>有可能遇到全部配置好之后网页访问返回refuse<ul>
<li>关闭selinux：setenforce 0</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/19/Build-Gitlab-in-CentOS7/" data-id="ck337q4de000s1cfyms5tvric" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tools/">Tools</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-RetinaNet-Focal-Loss-for-Dense-Object-Detection" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/19/RetinaNet-Focal-Loss-for-Dense-Object-Detection/" class="article-date">
  <time datetime="2018-07-19T10:14:34.000Z" itemprop="datePublished">2018-07-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Paper-Reading/">Paper Reading</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/19/RetinaNet-Focal-Loss-for-Dense-Object-Detection/">RetinaNet: Focal Loss for Dense Object Detection </a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>You can find this paper <a href="https://arxiv.org/pdf/1708.02002.pdf" target="_blank" rel="noopener">here</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/19/RetinaNet-Focal-Loss-for-Dense-Object-Detection/" data-id="ck337q4hq00491cfy9pgvv1c8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Detection/">Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Build-Personal-Blog-with-WordPress" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/17/Build-Personal-Blog-with-WordPress/" class="article-date">
  <time datetime="2018-07-17T12:30:39.000Z" itemprop="datePublished">2018-07-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Engineering/">Engineering</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/17/Build-Personal-Blog-with-WordPress/">Build Personal Blog  with WordPress</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/17/Build-Personal-Blog-with-WordPress/" data-id="ck337q4dq000z1cfyuf7ud1ap" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tools/">Tools</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Build-Personal-Blog-with-Hexo-Github-Page" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/17/Build-Personal-Blog-with-Hexo-Github-Page/" class="article-date">
  <time datetime="2018-07-17T12:28:18.000Z" itemprop="datePublished">2018-07-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/17/Build-Personal-Blog-with-Hexo-Github-Page/">Build Personal Blog  with Hexo + Github Page</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/17/Build-Personal-Blog-with-Hexo-Github-Page/" data-id="ck337q4dn000x1cfyks7kn37a" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/2/">&laquo; 上一页</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Engineering/">Engineering</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper-Reading/">Paper Reading</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/3D/">3D</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Basic/">Basic</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bottom-UP/">Bottom UP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BottomUp/">BottomUp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bottom-Up/">Bottom_Up</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Classic/">Classic</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Classification/">Classification</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DeepLab/">DeepLab</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Detection/">Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Engineering/">Engineering</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Face/">Face</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hardware/">Hardware</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KeyPoint/">KeyPoint</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Landmark/">Landmark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Learning-Strategy/">Learning Strategy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Loss/">Loss</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mimick/">Mimick</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mobile/">Mobile</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mutual-learning/">Mutual learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Platform/">Platform</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pose/">Pose</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Quantization/">Quantization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Regularization/">Regularization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SOT/">SOT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Segmentation/">Segmentation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Template/">Template</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tools/">Tools</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Track/">Track</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tracking/">Tracking</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VID/">VID</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/3D/" style="font-size: 10px;">3D</a> <a href="/tags/Basic/" style="font-size: 10px;">Basic</a> <a href="/tags/Bottom-UP/" style="font-size: 10px;">Bottom UP</a> <a href="/tags/BottomUp/" style="font-size: 16.67px;">BottomUp</a> <a href="/tags/Bottom-Up/" style="font-size: 10px;">Bottom_Up</a> <a href="/tags/Classic/" style="font-size: 13.33px;">Classic</a> <a href="/tags/Classification/" style="font-size: 10px;">Classification</a> <a href="/tags/DeepLab/" style="font-size: 10px;">DeepLab</a> <a href="/tags/Detection/" style="font-size: 20px;">Detection</a> <a href="/tags/Engineering/" style="font-size: 10px;">Engineering</a> <a href="/tags/Face/" style="font-size: 15px;">Face</a> <a href="/tags/Hardware/" style="font-size: 10px;">Hardware</a> <a href="/tags/KeyPoint/" style="font-size: 13.33px;">KeyPoint</a> <a href="/tags/Landmark/" style="font-size: 18.33px;">Landmark</a> <a href="/tags/Learning-Strategy/" style="font-size: 10px;">Learning Strategy</a> <a href="/tags/Loss/" style="font-size: 11.67px;">Loss</a> <a href="/tags/Mimick/" style="font-size: 11.67px;">Mimick</a> <a href="/tags/Mobile/" style="font-size: 10px;">Mobile</a> <a href="/tags/Mutual-learning/" style="font-size: 10px;">Mutual learning</a> <a href="/tags/Platform/" style="font-size: 10px;">Platform</a> <a href="/tags/Pose/" style="font-size: 15px;">Pose</a> <a href="/tags/Quantization/" style="font-size: 10px;">Quantization</a> <a href="/tags/Regularization/" style="font-size: 11.67px;">Regularization</a> <a href="/tags/SOT/" style="font-size: 10px;">SOT</a> <a href="/tags/Segmentation/" style="font-size: 16.67px;">Segmentation</a> <a href="/tags/Template/" style="font-size: 10px;">Template</a> <a href="/tags/Tools/" style="font-size: 13.33px;">Tools</a> <a href="/tags/Track/" style="font-size: 11.67px;">Track</a> <a href="/tags/Tracking/" style="font-size: 10px;">Tracking</a> <a href="/tags/VID/" style="font-size: 13.33px;">VID</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">六月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">三月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">十一月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">十月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">九月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/06/28/Look-at-Boundary-A-Boundary-Aware-Face-Alignment-Algorithm/">Look at Boundary: A Boundary-Aware Face Alignment Algorithm</a>
          </li>
        
          <li>
            <a href="/2019/06/28/Quantization-Mimic-Towards-Very-Tiny-CNN-for-Object-Detection/">Quantization Mimic: Towards Very Tiny CNN for Object Detection</a>
          </li>
        
          <li>
            <a href="/2019/06/24/Mimicking-Very-Efficient-Network-for-Object-Detection/">Mimicking Very Efficient Network for Object Detection</a>
          </li>
        
          <li>
            <a href="/2019/06/20/Tone-Mapping/">Tone Mapping</a>
          </li>
        
          <li>
            <a href="/2019/06/15/Lightweight-Real-time-Makeup-Try-on-in-Mobile-Browsers-with-Tiny-CNN-Models-for-Facial-Tracking/">Lightweight Real-time Makeup Try-on in Mobile Browsers with Tiny CNN Models for Facial Tracking</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 DreamHigh<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>