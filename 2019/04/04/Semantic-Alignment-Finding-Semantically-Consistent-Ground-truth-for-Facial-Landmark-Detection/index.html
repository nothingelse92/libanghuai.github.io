<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Live and Learn"><title>Semantic Alignment: Finding Semantically Consistent Ground-truth for Facial Landmark Detection | Out of Memory</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Semantic Alignment: Finding Semantically Consistent Ground-truth for Facial Landmark Detection</h1><a id="logo" href="/.">Out of Memory</a><p class="description">Live and Learn</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Semantic Alignment: Finding Semantically Consistent Ground-truth for Facial Landmark Detection</h1><div class="post-meta">Apr 4, 2019<script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><a class="disqus-comment-count" href="/2019/04/04/Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection/#vcomment"><span class="valine-comment-count" data-xid="/2019/04/04/Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection/"></span><span> 条评论</span></a><div class="post-content"><p>URL:<a href="https://arxiv.org/abs/1903.10661" target="_blank" rel="noopener">https://arxiv.org/abs/1903.10661</a><br>CVPR2019最新挂出来的一篇关于人脸landmark的论文，论文的出发点是觉得目前landmark定位精度受限于部分标注点”语意”模糊有关,比如说脸部轮廓点或者眼部轮廓点不像眼球、鼻尖这些点有明确的语意定义，因此标注引入的误差就相对影响比较大。所以作者从这方面入手在模型每次迭代的时候去寻找这样一个“真正”的gt来监督网络的训练，此外为了来修正一些偏移比较厉害的点，作者又引入了一个子网络来refine整体的landmark。这篇论文整体个人感觉很有意义。</p>
<p>首先作者是利用4个级联的Hourglass结构网络来进行landmark点定位的，下图是作者可视化语意明确和语意不明确点在输出heatmap上的结果，在2D空间可以发现，语意比较明确的点比如眼球中心点它的分布更加接近高斯分布，在3D空间这些点的分布更加的锐利，而语意不明确的点比如轮廓点在3D空间就会形如一个“flat hat”：<br><img src="Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection-屏幕快照 2019-04-03 下午11.53.38.png" alt><br>同时当网络已经差不多收敛的时候如果继续训练也会发现那些语意不明确的点依然在gt附近来回抖动，这也一定程度上验证了语意不明确导致标注带来的noise。<br>从网络输出的heatmap上出landamrk点可以将landmark点理解为一种数据分布，w为网络权重、x为输入图片、o为landmark点：<br><img src="Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection-3043ff99afa634151fd3e0f785d7b1dbfbdd0c63.png" alt><br>那么既然gt也不是那么的准确，作者不妨就假设目前存在这样一个真正的gt，不会引入任何的语意不确定性，那么上述的公式可以表示为，y为定义的真正的gt, 那么o就可以理解为是y的一个观测值：<br><img src="Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection-77c089022e93074fcd6ae6a27cff0e58657635b3.png" alt><br>为了缩小后续的搜索空间作者做了一个合理的假定：y<sup>k</sup>存在于o<sup>k</sup>的附近，所以可以用高斯相似度来衡量这种先验概率：<br><img src="Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection-e1fa30cf7bebe4160d61ca0066ab6f041513d19c.png" alt><br>而至于公式的后半段似然概率作者认为对于模型输出的heatmap，如果位置(x, y)周围的region越符合高斯分布，那么点(x, y )就更接近y这样的真正的gt, 所以作者就利用两个分布（预测分布，实际分布(y的分布)）之间的相似度来度量这个似然概率，Φ为抠patch的操作，E为真正gt的分布：<br><img src="Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection-b8ba7247a1f5ce534923f05834a51f56ae2145cd.png" alt><br><img src="Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection-9d0211bc90065c7cb20afa4bd494d72283d417cc.png" alt><br>那么通过简单的转化就可以把前面的优化目标转换为，N(ok)可以理解为以点ok为中心的一小部分区域，其实也就是y的搜索空间：<br><img src="Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection-屏幕快照 2019-04-04 下午12.58.56.jpg" alt><br><img src="Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection-9774dd8b68edeb975c901d5289f5bed290e42e57.png" alt><br>那么在实际做的时候，作者将整个方法的优化分成两部分来进行，第一步是固定模型的参数W，去搜索最好的y，因为一旦w固定除了yk其他都是已知的，所以直接去搜索y<sup>k</sup>,搜索空间实际应该是o<sup>k</sup>为中心的17x17大小的区域，那么第一个iteration，标注结果就是gt，在二个iteration，前一个iteration搜索得到的y就是gt，依次类推。第二步是固定y去训练模型的参数W，然后这一步就是具体的模型训练了，训练目标为：<br><img src="Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection-d29dc1db9c88f3c357b807b8cf756a1e40ffb5db.png" alt><br>因为从模型的输出直接出landmark点没有完全的考虑脸的整个形态，更多的是考虑了单个点的相关信息，所以作者最后加了一个GHCU的模块来refine landmark点：<br><img src="Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection-屏幕快照 2019-04-04 下午1.10.55.png" alt><br><img src="Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection-屏幕快照 2019-04-04 下午1.12.28.png" alt><br>300-W上的实验结果：<br><img src="Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection-屏幕快照 2019-04-04 下午1.13.23.png" alt><br>AFLW的实验结果：<br><img src="Semantic-Alignment-Finding-Semantically-Consistent-Ground-truth-for-Facial-Landmark-Detection-屏幕快照 2019-04-04 下午1.14.02.png" alt><br>感觉作者的想法还是很make sense的，目前我们正在用的landmark标注数据也存在这样的语意模糊导致引入标注误差的问题，但是这种标注误差带来的影响还是和实际的任务比较相关，从论文给出的例子来看，预测的landmark点通常在gt附近有一定的抖动，如果这种抖动是贴合轮廓这个影响就相对比较小</p>
</div><div class="tags"><a href="/tags/Landmark/">Landmark</a></div><div class="post-nav"><a class="pre" href="/2019/04/10/Spatial-Transformer-Networks/">Spatial Transformer Networks</a><a class="next" href="/2019/03/25/Object-Detection-based-on-Region-Decomposition-and-Assembly/">Object Detection based on Region Decomposition and Assembly</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'true' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'kJG6YxzEHXemVJF63TTH3GrX-gzGzoHsz',
  appKey:'o4lqtg6IRJ10QYXGuUJ2YLEC',
  placeholder:'我来说两句~',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="http://yoursite.com"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Engineering/">Engineering</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper-Reading/">Paper Reading</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Loss/" style="font-size: 15px;">Loss</a> <a href="/tags/Mobile/" style="font-size: 15px;">Mobile</a> <a href="/tags/Platform/" style="font-size: 15px;">Platform</a> <a href="/tags/Hardware/" style="font-size: 15px;">Hardware</a> <a href="/tags/Detection/" style="font-size: 15px;">Detection</a> <a href="/tags/Landmark/" style="font-size: 15px;">Landmark</a> <a href="/tags/KeyPoint/" style="font-size: 15px;">KeyPoint</a> <a href="/tags/BottomUp/" style="font-size: 15px;">BottomUp</a> <a href="/tags/Bottom-Up/" style="font-size: 15px;">Bottom_Up</a> <a href="/tags/Pose/" style="font-size: 15px;">Pose</a> <a href="/tags/Tools/" style="font-size: 15px;">Tools</a> <a href="/tags/Engineering/" style="font-size: 15px;">Engineering</a> <a href="/tags/Mutual-learning/" style="font-size: 15px;">Mutual learning</a> <a href="/tags/Classification/" style="font-size: 15px;">Classification</a> <a href="/tags/Segmentation/" style="font-size: 15px;">Segmentation</a> <a href="/tags/Regularization/" style="font-size: 15px;">Regularization</a> <a href="/tags/VID/" style="font-size: 15px;">VID</a> <a href="/tags/Face/" style="font-size: 15px;">Face</a> <a href="/tags/SOT/" style="font-size: 15px;">SOT</a> <a href="/tags/Tracking/" style="font-size: 15px;">Tracking</a> <a href="/tags/Track/" style="font-size: 15px;">Track</a> <a href="/tags/Mimick/" style="font-size: 15px;">Mimick</a> <a href="/tags/3D/" style="font-size: 15px;">3D</a> <a href="/tags/Template/" style="font-size: 15px;">Template</a> <a href="/tags/Bottom-UP/" style="font-size: 15px;">Bottom UP</a> <a href="/tags/DeepLab/" style="font-size: 15px;">DeepLab</a> <a href="/tags/Learning-Strategy/" style="font-size: 15px;">Learning Strategy</a> <a href="/tags/Classic/" style="font-size: 15px;">Classic</a> <a href="/tags/Basic/" style="font-size: 15px;">Basic</a> <a href="/tags/Quantization/" style="font-size: 15px;">Quantization</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/06/28/Look-at-Boundary-A-Boundary-Aware-Face-Alignment-Algorithm/">Look at Boundary: A Boundary-Aware Face Alignment Algorithm</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/28/Quantization-Mimic-Towards-Very-Tiny-CNN-for-Object-Detection/">Quantization Mimic: Towards Very Tiny CNN for Object Detection</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/24/Mimicking-Very-Efficient-Network-for-Object-Detection/">Mimicking Very Efficient Network for Object Detection</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/20/Tone-Mapping/">Tone Mapping</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/15/Lightweight-Real-time-Makeup-Try-on-in-Mobile-Browsers-with-Tiny-CNN-Models-for-Facial-Tracking/">Lightweight Real-time Makeup Try-on in Mobile Browsers with Tiny CNN Models for Facial Tracking</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/10/Improving-Landmark-Localization-with-Semi-Supervised-Learning/">Improving Landmark Localization with Semi-Supervised Learning</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/05/Seeing-Small-Faces-from-Robust-Anchor’s-Perspective/">Seeing Small Faces from Robust Anchor’s Perspective</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/01/Style-Aggregated-Network-for-Facial-Landmark-Detection/">Style Aggregated Network for Facial Landmark Detection</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/25/Deep-Regionlets-for-Object-Detection/">Deep Regionlets for Object Detection</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/21/Regionlets-for-Generic-Object-Detection/">Regionlets for Generic Object Detection</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/libanghuai" title="Github" target="_blank">Github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">Out of Memory.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" color="0,0,0" opacity="0.5" zindex="-2" count="50" src="//lib.baomitu.com/canvas-nest.js/2.0.3/canvas-nest.umd.js"></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>